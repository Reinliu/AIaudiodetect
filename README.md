# AI audio detection

### An implementation on AI audio detection based on Fourier theorem.

This implementation is based on paper: https://arxiv.org/abs/2506.19108
which aims to detect periodic artifacts generated by transposed CNN layers. It was known that AI audio generative models typically use either transpose1dCNN or transpose2dCNN to upsample audio or the spectrograms. Though subtle to human perception, they exist in a periodic pattern and can be detected by employing a simple CNN model using a regression loss. 

### Preprocess:

First you need to prepare an audio dataset. In my case I used the FMA dataset: https://github.com/mdeff/fma. After downloading the dataset into your directory, you can use the 'gen.py' to generate artifact audios using Encodec.

### Train:

You can use the train.py to train the model.

### Inference:

I have prepared a gradio interactive interface so that you could run it on a server and enable others to play with the tool.
